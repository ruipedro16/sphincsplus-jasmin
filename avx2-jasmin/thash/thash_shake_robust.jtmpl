from Sphincs require "fips202/shake256_array/shake256.jtmpl"
from Sphincs require "memcpy/memcpy.jtmpl"

inline fn __thash<INBLOCKS>(
  reg ptr u8[SPX_N] out,
  reg ptr u8[INBLOCKS*SPX_N] in,
  reg ptr u8[SPX_N] pub_seed,
  reg ptr u32[8] addr)
  ->
  reg ptr u8[SPX_N]
{
  stack   u8[SPX_N + SPX_ADDR_BYTES + INBLOCKS*SPX_N] buf;
  reg ptr u8[SPX_N + SPX_ADDR_BYTES + INBLOCKS*SPX_N] buf_p;
  reg ptr u8[SPX_N + SPX_ADDR_BYTES]                  buf_ps;

  stack   u8[INBLOCKS*SPX_N] bitmask;
  reg ptr u8[INBLOCKS*SPX_N] bitmask_p;

  reg u64 i offset;
  stack u64 offset_s;
  reg u8 b;

  () = #spill(in, out);
  
  buf_p = buf;
  offset = 0;

  buf_p, offset = _x_memcpy_u8u8<SPX_N + SPX_ADDR_BYTES + INBLOCKS*SPX_N, SPX_N>(buf_p, offset, pub_seed);
  buf_p, offset = _x_memcpy_u8u32<SPX_N + SPX_ADDR_BYTES + INBLOCKS*SPX_N, 8>(buf_p, offset, addr);

  buf = buf_p;
  () = #spill(offset);

  bitmask_p = bitmask;
  buf_ps = buf[0:(SPX_N + SPX_ADDR_BYTES)];
  bitmask_p = __shake256<INBLOCKS*SPX_N,SPX_N + SPX_ADDR_BYTES>(bitmask_p, buf_ps);

  // TODO: optimize
  i = 0;
  () = #unspill(in, offset);
  while(i < INBLOCKS*SPX_N)
  { b  = in[i];
    b ^= bitmask_p[i];
    buf[offset] = b;
    offset += 1;
    i += 1;
  }

  () = #unspill(out);
  buf_p = buf;
  out = __shake256<SPX_N, SPX_N + SPX_ADDR_BYTES + INBLOCKS*SPX_N>(out, buf_p);

  return out;
}//<>

#[returnaddress="stack"]
fn _thash<INBLOCKS>(
  reg ptr u8[SPX_N] out,
  reg ptr u8[INBLOCKS*SPX_N] in,
  reg ptr u8[SPX_N] pub_seed,
  reg ptr u32[8] addr
) -> reg ptr u8[SPX_N]
{
  out = __thash<INBLOCKS>(out, in, pub_seed, addr);
  return out;
}//<>

inline fn __thash_<INBLOCKS>(
  reg ptr u8[SPX_N] out,
  reg ptr u8[INBLOCKS*SPX_N] in,
  reg ptr u8[SPX_N] pub_seed,
  reg ptr u32[8] addr
) -> reg ptr u8[SPX_N]
{
  out = out; in = in; pub_seed = pub_seed; addr = addr;
  out = _thash<INBLOCKS>(out, in, pub_seed, addr);
  out = out; in = in; pub_seed = pub_seed; addr = addr;

  return out;
}//<>

//////////////////////////////////////////////////////////////////
inline fn __thash_inplace(
  reg ptr u8[SPX_N] out,
  reg ptr u8[SPX_N] pub_seed,
  reg ptr u32[8] addr
) -> reg ptr u8[SPX_N]
{
  stack   u8[SPX_N + SPX_ADDR_BYTES + SPX_N] buf;
  reg ptr u8[SPX_N + SPX_ADDR_BYTES + SPX_N] buf_p;
  reg ptr u8[SPX_N + SPX_ADDR_BYTES]         buf_ps;

  stack   u8[SPX_N] bitmask;
  reg ptr u8[SPX_N] bitmask_p;

  reg u64 i offset;
  reg u8 b;

  () = #spill(out);
  buf_p = buf;
  offset = 0;

  buf_p, offset = _x_memcpy_u8u8<SPX_N + SPX_ADDR_BYTES + SPX_N, SPX_N>(buf_p, offset, pub_seed);
  buf_p, offset = _x_memcpy_u8u32<SPX_N + SPX_ADDR_BYTES + SPX_N, 8>(buf_p, offset, addr);

  buf = buf_p;
  () = #spill(offset);

  bitmask_p = bitmask;
  buf_ps = buf[0:(SPX_N + SPX_ADDR_BYTES)];
  bitmask_p = __shake256<SPX_N,SPX_N + SPX_ADDR_BYTES>(bitmask_p, buf_ps);

  // TODO: optimize
  () = #unspill(out);
  i = 0;
  () = #unspill(offset);
  while(i < SPX_N)
  { b  = out[i];
    b ^= bitmask_p[i];
    buf[offset] = b;
    offset += 1;
    i += 1;
  }

  buf_p = buf;
  out = __shake256<SPX_N, SPX_N + SPX_ADDR_BYTES + SPX_N>(out, buf_p);

  return out;
}

#[returnaddress="stack"]
fn _thash_inplace(
  reg ptr u8[SPX_N] out,
  reg ptr u8[SPX_N] pub_seed,
  reg ptr u32[8] addr
) -> reg ptr u8[SPX_N]
{
  out = __thash_inplace(out, pub_seed, addr);
  return out;
}//<>

inline fn __thash_inplace_(
  reg ptr u8[SPX_N] out,
  reg ptr u8[SPX_N] pub_seed,
  reg ptr u32[8] addr
) -> reg ptr u8[SPX_N]
{
  out = out; pub_seed = pub_seed; addr = addr;
  out = _thash_inplace(out, pub_seed, addr);
  out = out; pub_seed = pub_seed; addr = addr;

  return out;
}//<>

//// THASH BUT OUT IS A REG U64 INSTEAD OF A REG PTR U8[SPX_N]
inline fn __thash_in_u64<INBLOCKS>(
  reg ptr u8[SPX_N] out,
  reg u64 in, // reg ptr u8[INBLOCKS*SPX_N] in,
  reg ptr u8[SPX_N] pub_seed,
  reg ptr u32[8] addr
) -> reg ptr u8[SPX_N]
{
  stack   u8[SPX_N + SPX_ADDR_BYTES + INBLOCKS*SPX_N] buf;
  reg ptr u8[SPX_N + SPX_ADDR_BYTES + INBLOCKS*SPX_N] buf_p;
  reg ptr u8[SPX_N + SPX_ADDR_BYTES]                  buf_ps;

  stack   u8[INBLOCKS*SPX_N] bitmask;
  reg ptr u8[INBLOCKS*SPX_N] bitmask_p;

  reg u64 i offset;
  reg u8 b;

  () = #spill(in, out);
  buf_p = buf;
  offset = 0;

  buf_p, offset = _x_memcpy_u8u8<SPX_N + SPX_ADDR_BYTES + INBLOCKS*SPX_N, SPX_N>(buf_p, offset, pub_seed);
  buf_p, offset = _x_memcpy_u8u32<SPX_N + SPX_ADDR_BYTES + INBLOCKS*SPX_N, 8>(buf_p, offset, addr);

  buf = buf_p;
  () = #spill(offset);

  bitmask_p = bitmask;
  buf_ps = buf[0:(SPX_N + SPX_ADDR_BYTES)];
  bitmask_p = __shake256<INBLOCKS*SPX_N,SPX_N + SPX_ADDR_BYTES>(bitmask_p, buf_ps);

  // TODO: optimize
  () = #unspill(in, offset);
  i = 0;
  while(i < INBLOCKS*SPX_N)
  { b  = (u8)[in + i];
    b ^= bitmask_p[i];
    buf[offset] = b;
    offset += 1;
    i += 1;
  }

  () = #unspill(out);
  buf_p = buf;
  out = __shake256<SPX_N, SPX_N + SPX_ADDR_BYTES + INBLOCKS*SPX_N>(out, buf_p);

  return out;
}//<>

#[returnaddress="stack"]
fn _thash_in_u64<INBLOCKS>(
  reg ptr u8[SPX_N] out,
  reg u64 in, //reg ptr u8[INBLOCKS*SPX_N] in,
  reg ptr u8[SPX_N] pub_seed,
  reg ptr u32[8] addr
) -> reg ptr u8[SPX_N]
{
  out = __thash_in_u64<INBLOCKS>(out, in, pub_seed, addr);
  return out;
}//<>

inline fn __thash_in_u64_<INBLOCKS>(
  reg ptr u8[SPX_N] out,
  reg u64 in, // reg ptr u8[INBLOCKS*SPX_N] in,
  reg ptr u8[SPX_N] pub_seed,
  reg ptr u32[8] addr
) -> reg ptr u8[SPX_N]
{
  out = out; in = in; pub_seed = pub_seed; addr = addr;
  out = _thash_in_u64<INBLOCKS>(out, in, pub_seed, addr);
  out = out;
  return out;
}//<>